<html>
  <head>
    <link href="../imp.css" rel="stylesheet">
    <title>Binomial Distribution</title>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="../MathJax/es5/tex-mml-chtml.js">
    </script>
  </head>
  <body>
    <div class="back"> <a href="ProThe.html">Back</a> </div>
    This section is aimed at students in upper secondary education in the Danish
    school system, some objects will be simplified some details will be omitted.
    <div class="def"><center><h1> Bernoulli Process </h2></center>
      A bernoulli process is a sequence of random events that conform to the
      following two conditions:<br>
      <center>1. Each event has two possible outcomes, colloquially referred to as
      success and failure.</center>
      <center>2. The probability of success for each event is equal.</center>
    </div>
      Sometimes it is required that the events be independent, and
      mathematically they are, but you can construct situations where the events
      are not strictly independent but mathematically independent. Consider a
      game where you have a coin and two differently coloured dice. You flip
      the coin and if it lands heads, you throw one die and consider an even
      number of eyes a success, if its tails you throw the other and odd number
      eyes is a success. Mathematically these events are independent but
      intuitively they are not, but it can still be considered a Bernoulli
      process.
    <div class="def"><center><h1> Binomial Distribution </h1></center>
      A binomial distribution describes the probability of getting a certain
      number of successes in a Bernoulli process. It can be calculated as
      follows
        $$P(X=r)={n\choose r}p^r(1-p)^{n-r}$$
      where \(n\in\mathbb{N}\) is the number of events, \(p\in[0,1]\) is the
      probability of success and \(r\in[0,n]\cap\mathbb{N}\) is the number of
      successes. Conversely, if we have a discrete random variable \(X\)
      that conforms to this formula, it is said to be binomially distributed
      denoted as \(X\sim B(n,p)\).</div>
      The first factor
        $${n\choose r}=\frac{n!}{r!(n-r)!}$$
      is the number of ways I can get \(r\) successes in \(n\) events since we
      assume that the order of successes is irrelevant. To calculate the
      probability of an outcome in a Bernoulli process, we just multiply the
      probability of the outcome of each event, since they're mathematically
      independent. Since multiplication is commutative, this means we can just
      gather all the successes and failures into two factors, \(p^r\) and
      \((1-p)^{n-r}\) respectively, since if there are \(r\) successes the rest,
      \(n-r\), must be failures, with probability \(1-p\).
    <div class="thm"><center><h1> Theorem(Expected Value) </h1></center>
      For a binomially distributed random variable \(X\sim b(n,p)\) we can
      calculate the expected value and variance as
      \begin{align}
        E(X)=&np\\
        Var(X)=&E(x)(1-p)\\
        =&np(1-p)
      \end{align}
    </div>
      In the proof, I will use the following statement on combinatorics
      <div class="lem"><center><h2> Lemma(Combinations) </h2></center>
          $$r{n\choose r}=n{n-1\choose r-1}$$
      </div>
      which is proven in <a href="Com.html">this</a> section.
      <h2> Proof of Theorem </h2>
        I will start by proving the statement for the expected value
        \begin{align}
          E(X)=&\sum_{r=0}^n r⋅P(X=r)\\
          =&\sum_{r=0}^n r⋅{n\choose r}p^r(1-p)^{n-r}\\
          =&p\sum_{r=1}^n n⋅{n-1\choose r-1}p^{r-1}(1-p)^{n-1-(r-1)}\\
          =&np\sum_{k=0}^m {m\choose k}p^k(1-p)^{m-k}\\
          =&np\sum_{k=0}^m P(Y=k)=np⋅1=np
        \end{align}
        where I start by using the definition of the expected value. Then I use
        the formula for the probabability for a specific random value.
        Afterwards I use the lemma, move one of the p's outside the sum and add
        and subtract a 1 from the last exponent. Then I change the variables
        into \(k=r-1\) and \(m=n-1\) and move the n outside the sum. If \(r\)
        goes from 1 to \(n\) then \(k=r-1\) goes from 0 to \(n-1=m\). This
        yields the sum of the probabilities of all the different random values
        for the binomial distribution \(Y\sim b(n-1,p)\), which is the whole
        sample space so the probability is 1 since "something has to happen".
        The proof of the variance formula is similar, but slightly more
        involved.
        \begin{align}
          Var(X)=&\sum_{r=0}^n(r-μ)^2P(X=r)\\
          =&\sum_{r=0}^n(r-np)^2{n\choose r}p^r(1-p)^{n-r}\\
          =&\sum_{r=0}^n(r^2-2npr+n^2p^2){n\choose r}p^r(1-p)^{n-r}\\
          =&n^2p^2\cancel{\sum_{r=0}^n{n\choose r}p^r(1-p)^{n-r}}\\
          &-2np\sum_{r=1}^n r{n\choose r}p^r(1-p)^{n-r}\\
          &+\sum_{r=1}^n r^2{n\choose r}p^r(1-p)^{n-r}\\
          =&n^2p^2-2np⋅E(X)+\sum_{r=1}^n r^2{n\choose r}p^r(1-p)^{n-r}
        \end{align}
        The first two terms just reduce to \(-n^2p^2\) so we just need to figure
        out the last sum. We start by using the lemma once to yield
          $$\sum_{r=1}^n r^2{n\choose r}p^r(1-p)^{n-r}=\sum_{r=1}^n r
          n{n-1\choose r-1}p^r(1-p)^{n-r}$$
        We still have an \(r\) in the sum, so we do a classic math trick and
        add and subtract a term that allows us to use the lemma again
        \begin{align}
          &n\sum_{r=1}^n {n-1\choose r-1}p^r(1-p)^{n-r}+
          n\sum_{r=1}^n r{n-1\choose r-1}p^r(1-p)^{n-r}-n\sum_{r=1}^n
          {n-1\choose r-1}p^r(1-p)^{n-r}\\
          =&np\cancel{\sum_{r=1}^n{n-1\choose r-1}p^{r-1}(1-p)^{n-1-(r-1)}}
          +n\sum_{r=2}^n (r-1){n-1\choose r-1}p^r(1-p)^{n-r}\\
          =&np+n\sum_{r=2}^n (n-1){n-2\choose r-2}p^r(1-p)^{n-r}\\
          =&np+n(n-1)p^2\cancel{\sum_{r=2}^n{n-2\choose r-2}p^{r-2}
          (1-p)^{n-2-(r-2)}}
        \end{align}
        All in all, we end up with
          $$Var(X)=-n^2p^2+np+n(n-1)p^2=\cancel{-n^2p^2}+np-np^2-
          \cancel{n^2p^2}=np(1-p)$$
          <p style="text-align:center;">&#x220E;</p>
  </body>
</html>
